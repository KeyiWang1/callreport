{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652d9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "import xport, csv\n",
    "import pandas as pd\n",
    "from pandas.api.types import infer_dtype\n",
    "from datetime import datetime\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756323f9",
   "metadata": {},
   "source": [
    "Define the urls to extract from and the download folder directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7aa545",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1976_2000 = 'https://www.chicagofed.org/banking/financial-institution-reports/commercial-bank-data-complete-1976-2000'\n",
    "# use selenium for 2001-present\n",
    "root = 'https://www.chicagofed.org/'\n",
    "# change the download_folder to your local directory\n",
    "download_folder = 'C:/Users/kwang648/Downloads/banking/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce86ee3",
   "metadata": {},
   "source": [
    "define start and end quarter for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48d3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '202203' # format:YYYYMM\n",
    "end = '202303' # format:YYYYMM\n",
    "start =  datetime.strptime(start, '%Y%m')\n",
    "end =  datetime.strptime(end, '%Y%m')\n",
    "quarters = (pd.date_range(start,end + pd.offsets.QuarterBegin(1), freq='Q').strftime('%y%m').tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f524a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_links(url_list):\n",
    "    zip_files = []\n",
    "    for url in url_list:\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        all_hrefs = soup.find_all('a')\n",
    "        all_links = [link.get('href') for link in all_hrefs]\n",
    "        temp = [dl for dl in all_links if '.zip' in dl or '.ZIP' in dl]\n",
    "        temp = [dl.lower() for dl in temp]\n",
    "        temp = [dl[:dl.index('.zip')+len('.zip')] for dl in temp]\n",
    "        for dl in temp:\n",
    "            zip_files.append(dl)\n",
    "    return zip_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fab9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_zip(zip_files):\n",
    "    #if download folder does not exist, create one\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    for zip_file in zip_files:\n",
    "        if re.findall(\"[0-9]{4}\",zip_file)[0] in quarters:\n",
    "            full_url = root + zip_file\n",
    "            r = requests.get(full_url)\n",
    "            zip_filename = os.path.basename(zip_file)\n",
    "            dl_path = os.path.join(download_folder, zip_filename)\n",
    "            with open(dl_path, 'wb') as z_file:\n",
    "                z_file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c10e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used to extract the links after 2001\n",
    "def use_selenium(start,end):\n",
    "    if start >= datetime.strptime('200103', '%Y%m'):\n",
    "        quarters = (pd.date_range(start, end + pd.offsets.QuarterBegin(1), freq='Q').strftime('%m/%d/%Y').tolist())\n",
    "    else:\n",
    "        quarters = (pd.date_range(pd.to_datetime('200103',format='%Y%m'), pd.to_datetime(end) + pd.offsets.QuarterBegin(1), freq='Q').strftime('%m/%d/%Y').tolist())\n",
    "    # Create Driver Instance\n",
    "    options = webdriver.ChromeOptions()\n",
    "    prefs = {\"download.default_directory\":'C:\\\\Users\\\\kwang648\\\\Downloads\\\\banking'}\n",
    "    options.add_experimental_option(\"prefs\",prefs)\n",
    "    driver = webdriver.Chrome(service=Service(executable_path='C:/Users/kwang648/Downloads/python_code/chromedriver_win32/chromedriver.exe'),options=options)\n",
    "    url = 'https://cdr.ffiec.gov/public/PWS/DownloadBulkData.aspx'\n",
    "    driver.get(url)\n",
    "    #select \"call report\"\n",
    "    products = Select(driver.find_element(By.ID,'ListBox1'))\n",
    "    products.select_by_visible_text('Call Reports -- Single Period')\n",
    "    #select TSV for the format\n",
    "    driver.find_element(By.ID,'TSVRadioButton').click()\n",
    "    for period in quarters:\n",
    "        #drop down to select dates\n",
    "        dropdown = Select(driver.find_element(By.XPATH,'//*[@id=\"DatesDropDownList\"]'))\n",
    "        dropdown.select_by_visible_text(period)\n",
    "        #click download button\n",
    "        download_button = driver.find_element(By.ID,\"Download_0\")\n",
    "        download_button.click()\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03d484ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_filename(directory):\n",
    "    os.chdir(directory)\n",
    "    for item in os.listdir(directory):\n",
    "        if bool(re.search('[0-9]{8}.zip', item)):\n",
    "            new_name = re.findall('[0-9]{8}', item)[0]\n",
    "            new_name = \"call\"+datetime.strptime(new_name, '%m%d%Y').strftime('%y%m')+\".zip\"\n",
    "            os.rename(item,new_name)\n",
    "        if bool(re.search('[a-zA-Z]{4}[0-9]{4}.xpt', item)):\n",
    "            new_name = re.findall('[a-zA-Z]{4}[0-9]{4}.xpt', item)[0]\n",
    "            os.rename(item,new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eff7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip():\n",
    "    os.chdir(download_folder)\n",
    "    for item in os.listdir(download_folder):\n",
    "        if item.endswith('.zip'):\n",
    "            folder_name = re.search('[a-zA-Z]{4}[0-9]{4}', item)[0]\n",
    "            if not os.path.exists(download_folder+folder_name):\n",
    "                os.mkdir(download_folder+folder_name)\n",
    "            file_name = os.path.abspath(item)\n",
    "            zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "            zip_ref.extractall(download_folder+folder_name) # extract file to dir\n",
    "            zip_ref.close() # close file\n",
    "            os.remove(file_name) # delete zipped file\n",
    "    print('unzip complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae357c",
   "metadata": {},
   "source": [
    "Download, rename, and unzip the files for each quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e72a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download():\n",
    "    if start <= datetime.strptime('200012', '%Y%m'):\n",
    "        if end <= datetime.strptime('200012', '%Y%m'):\n",
    "            download_zip(extract_links([url1976_2000]))\n",
    "        else:\n",
    "            download_zip(extract_links([url1976_2000]))\n",
    "            use_selenium(start,end)\n",
    "    else:\n",
    "        use_selenium(start,end)\n",
    "    print('download zip files complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92857f1a",
   "metadata": {},
   "source": [
    "load variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3346ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_code = pd.read_csv('C:/Users/kwang648/Downloads/test.csv')\n",
    "item_code = item_code.drop(['Notes','Description','citation'],axis=1)\n",
    "#need to update the currently in use definition to the current quarter\n",
    "item_code['end'] = item_code['end'].apply(lambda x: 20230630 if x==99991231 else x)\n",
    "#convert begin and end period to DateTime type\n",
    "item_code['begin']=pd.to_datetime(item_code['begin'],format='%Y%m%d')\n",
    "item_code['end']=pd.to_datetime(item_code['end'],format='%Y%m%d')\n",
    "item_code = item_code.dropna(subset=['var_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa271e48",
   "metadata": {},
   "source": [
    "extract item code used in the definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf4b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = []\n",
    "for code in item_code['item_code']:\n",
    "    list = re.findall(\"[a-zA-Z0-9]+\",code)\n",
    "    for item in list:\n",
    "        if item not in var_list:\n",
    "            var_list.append(item)\n",
    "var_list.extend(['IDRSSD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252744e6",
   "metadata": {},
   "source": [
    "handle data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0edde927",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = pd.read_csv('C:/Users/kwang648/Downloads/dtype_dict.csv')\n",
    "dtype_dict['item_code']=dtype_dict['item_code'].str.upper()\n",
    "dtype_dict = dict(zip(dtype_dict['item_code'], dtype_dict['dtype']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d50e14c",
   "metadata": {},
   "source": [
    "Convert text to csv, this function also filters the columns to only keep the columns used in the variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea4ac89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_csv(item):\n",
    "    os.chdir(download_folder+item)\n",
    "    merged = pd.DataFrame()\n",
    "    for text in os.listdir(download_folder+item):\n",
    "        if text == 'Readme.txt':\n",
    "            continue\n",
    "        curr_list =  pd.read_csv(text, delimiter = \"\\t\",engine='python',on_bad_lines='skip').columns.tolist()\n",
    "        load_list = [element for element in var_list if element in curr_list]\n",
    "        if len(load_list)==1:\n",
    "            continue\n",
    "        new = pd.read_csv(text, delimiter = \"\\t\",usecols=load_list,engine='python',on_bad_lines='skip')\n",
    "        new['IDRSSD'] = pd.to_numeric(new['IDRSSD'], errors='coerce')\n",
    "        new = new.dropna(subset=['IDRSSD'])\n",
    "        if merged.empty:\n",
    "            merged = new\n",
    "        else:\n",
    "            merged = merged.merge(new,on='IDRSSD',suffixes=('', '_remove'))\n",
    "            merged = merged.loc[:,~merged.columns.str.contains('Unnamed')]\n",
    "    merged.drop([i for i in merged.columns if 'remove' in i],axis=1, inplace=True)\n",
    "    time = int((datetime.strptime(re.findall('[0-9]{4}',item)[0], '%y%m')+relativedelta(day=31)).strftime('%Y%m%d'))\n",
    "    merged['RSSD9999'] = pd.Series([time for x in range(len(merged.index))],dtype=int)\n",
    "    merged.rename(columns={'IDRSSD':'RSSD9001'},inplace=True)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0f7d1",
   "metadata": {},
   "source": [
    "Convert xpt to csv, this function also filters the columns to only keep the items used in the variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92628842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xpt_to_csv(item):\n",
    "    os.chdir(download_folder+item)\n",
    "    for xpt in os.listdir(download_folder+item):\n",
    "        with open(xpt, 'rb') as f:\n",
    "            df = xport.to_dataframe(f)\n",
    "        total_list = df.columns.tolist()\n",
    "        load_list = [element for element in var_list if element in total_list]\n",
    "        df = df[[c for c in df.columns if c in load_list]]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8e3eb",
   "metadata": {},
   "source": [
    "convert and download the csv for each quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d92cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_download():\n",
    "    os.chdir(download_folder)\n",
    "    folder_list = os.listdir(download_folder)\n",
    "    if not os.path.exists(download_folder+'csv'):\n",
    "        os.mkdir(download_folder+'csv')\n",
    "    for item in folder_list:\n",
    "        if datetime.strptime(re.findall('[0-9]{4}',item)[0], '%y%m') >= datetime.strptime('200103', '%Y%m'):\n",
    "            new = text_to_csv(item)\n",
    "        else:\n",
    "            new = xpt_to_csv(item)\n",
    "        new.to_csv(download_folder+'csv/'+item+'.csv',index=False)\n",
    "        print('conversion of '+item+' to csv complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0b1449",
   "metadata": {},
   "source": [
    "merge quarters together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff10eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge():\n",
    "    os.chdir(download_folder+'csv/')\n",
    "    merged = pd.DataFrame()\n",
    "    first_time=1\n",
    "    for item in os.listdir(download_folder+'csv/'):\n",
    "        new = dd.read_csv(item,dtype=dtype_dict)\n",
    "        if first_time == 1:\n",
    "            merged = new\n",
    "            first_time = 0\n",
    "        else:\n",
    "            merged = dd.concat([merged,new])\n",
    "    print('merge quarters complete')\n",
    "    return merged.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13d85b",
   "metadata": {},
   "source": [
    "variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26600991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_code(code,list):\n",
    "    code_list = re.findall(\"[a-zA-Z0-9]+\",code)\n",
    "    for item in code_list:\n",
    "        if item not in list:\n",
    "            print(item+' is not available')\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a842694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_definition(call_report):\n",
    "    call_report.rename(columns={'RSSD9999':'DATE'},inplace=True)\n",
    "    call_report['DATE']=pd.to_datetime(call_report['DATE'],format='%Y%m%d')\n",
    "    for varname in item_code['var_name'].unique():\n",
    "        #find begin and end date\n",
    "        begin = item_code[item_code['var_name']==varname]['begin']\n",
    "        end = item_code[item_code['var_name']==varname]['end']\n",
    "        code = item_code[item_code['var_name']==varname]['item_code']\n",
    "        #handle variable definition with multiple periods\n",
    "        i = 1\n",
    "        while i<=len(begin):\n",
    "            if handle_missing_code(code.iloc[i-1],call_report.columns.to_list()) ==True:\n",
    "                i=i+1\n",
    "                continue\n",
    "            if len(code.iloc[i-1])==8:\n",
    "                call_report.loc[(call_report['DATE']>=begin.iloc[i-1]) &(call_report['DATE']<=end.iloc[i-1]),varname] = call_report[(call_report['DATE']>=begin.iloc[i-1]) &(call_report['DATE']<=end.iloc[i-1])][code.iloc[i-1]]\n",
    "            else:\n",
    "                call_report.loc[(call_report['DATE']>=begin.iloc[i-1]) &(call_report['DATE']<=end.iloc[i-1]),varname] = call_report[(call_report['DATE']>=begin.iloc[i-1]) &(call_report['DATE']<=end.iloc[i-1])].eval(code.iloc[i-1])\n",
    "            i=i+1\n",
    "    call_report.to_csv(download_folder+'call_report.csv',index=False)\n",
    "    print('Variable definition complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a090c",
   "metadata": {},
   "source": [
    "initiate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e881a412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download zip files complete\n",
      "unzip complete\n",
      "conversion of call2203 to csv complete\n",
      "conversion of call2206 to csv complete\n",
      "conversion of call2209 to csv complete\n",
      "conversion of call2212 to csv complete\n",
      "conversion of call2303 to csv complete\n",
      "merge quarters complete\n",
      "RSSD9999 is not available\n",
      "RSSD9348 is not available\n",
      "RSSD9210 is not available\n",
      "RCFD1975 is not available\n",
      "RCON2604 is not available\n",
      "RCON6645 is not available\n",
      "RCFD1600 is not available\n",
      "RCFD1766 is not available\n",
      "RCFD1400 is not available\n",
      "RCFD1400 is not available\n",
      "RCFD1350 is not available\n",
      "RCFDB987 is not available\n",
      "RCFD2146 is not available\n",
      "RCFD0400 is not available\n",
      "RCFD0390 is not available\n",
      "RCFD2800 is not available\n",
      "RCFDB993 is not available\n",
      "RCFD2850 is not available\n",
      "RCFD1935 is not available\n",
      "RCON2350 is not available\n",
      "RCON2350 is not available\n",
      "RCON2350 is not available\n",
      "RCON2604 is not available\n",
      "RCON2389 is not available\n",
      "RIAD4000 is not available\n",
      "RIAD4130 is not available\n",
      "RIAD4170 is not available\n",
      "RIADA517 is not available\n",
      "RIAD4218 is not available\n",
      "RIADA517 is not available\n",
      "RIADA518 is not available\n",
      "RIAD4174 is not available\n",
      "RIAD4174 is not available\n",
      "RIADA517 is not available\n",
      "RIAD4509 is not available\n",
      "RCONA514 is not available\n",
      "RCON3345 is not available\n",
      "RCONA529 is not available\n",
      "RCON3385 is not available\n",
      "RIAD4011 is not available\n",
      "RCONA579 is not available\n",
      "RCONA580 is not available\n",
      "RCONA581 is not available\n",
      "RCONA582 is not available\n",
      "RCONA241 is not available\n",
      "RCONA584 is not available\n",
      "RCONA585 is not available\n",
      "RCONA586 is not available\n",
      "RCONA587 is not available\n",
      "RCFD8729 is not available\n",
      "RCFD8729 is not available\n",
      "RCON2343 is not available\n",
      "RCON2344 is not available\n",
      "RSSD9048 is not available\n",
      "RSSD9348 is not available\n",
      "RSSD9010 is not available\n",
      "Variable definition complete\n"
     ]
    }
   ],
   "source": [
    "download()\n",
    "rename_filename(download_folder)\n",
    "unzip()\n",
    "for item in os.listdir(download_folder):\n",
    "    rename_filename(download_folder+item)\n",
    "convert_download()\n",
    "merged = merge()\n",
    "variable_definition(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee92f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
