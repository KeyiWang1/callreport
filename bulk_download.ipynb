{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652d9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "import xport, csv\n",
    "import pandas as pd\n",
    "from pandas.api.types import infer_dtype\n",
    "from datetime import datetime\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756323f9",
   "metadata": {},
   "source": [
    "Define the urls to extract from and the download folder directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7aa545",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1976_2000 = 'https://www.chicagofed.org/banking/financial-institution-reports/commercial-bank-data-complete-1976-2000'\n",
    "url2001_2010 = 'https://www.chicagofed.org/banking/financial-institution-reports/commercial-bank-data-complete-2001-2010'\n",
    "url2011_2021 = 'https://www.chicagofed.org/banking/financial-institution-reports/commercial-bank-structure-data'\n",
    "root = 'https://www.chicagofed.org/'\n",
    "download_folder = 'C:/Users/kwang648/Downloads/banking/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce86ee3",
   "metadata": {},
   "source": [
    "define start and end quarter for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48d3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '199802'\n",
    "end = '202203'\n",
    "start =  datetime.strptime(start, '%Y%m')\n",
    "end =  datetime.strptime(end, '%Y%m')\n",
    "quarters = (pd.date_range(start,end + pd.offsets.QuarterBegin(1), freq='Q').strftime('%y%m').tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f524a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_links(url_list):\n",
    "    zip_files = []\n",
    "    for url in url_list:\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        all_hrefs = soup.find_all('a')\n",
    "        all_links = [link.get('href') for link in all_hrefs]\n",
    "        temp = [dl for dl in all_links if '.zip' in dl or '.ZIP' in dl]\n",
    "        temp = [dl.lower() for dl in temp]\n",
    "        temp = [dl[:dl.index('.zip')+len('.zip')] for dl in temp]\n",
    "        for dl in temp:\n",
    "            zip_files.append(dl)\n",
    "    return zip_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fab9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_zip(zip_files):\n",
    "    #if download folder does not exist, create one\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    for zip_file in zip_files:\n",
    "        if re.findall(\"[0-9]{4}\",zip_file)[0] in quarters:\n",
    "            full_url = root + zip_file\n",
    "            r = requests.get(full_url)\n",
    "            zip_filename = os.path.basename(zip_file)\n",
    "            dl_path = os.path.join(download_folder, zip_filename)\n",
    "            with open(dl_path, 'wb') as z_file:\n",
    "                z_file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c10e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used to extract the links after 202106\n",
    "def use_selenium(start,end):\n",
    "    if start >= datetime.strptime('202109', '%Y%m'):\n",
    "        quarters = (pd.date_range(start, end + pd.offsets.QuarterBegin(1), freq='Q').strftime('%m/%d/%Y').tolist())\n",
    "    else:\n",
    "        quarters = (pd.date_range(pd.to_datetime('202109',format='%Y%m'), pd.to_datetime(end) + pd.offsets.QuarterBegin(1), freq='Q').strftime('%m/%d/%Y').tolist())\n",
    "    # Create Driver Instance\n",
    "    options = webdriver.ChromeOptions()\n",
    "    prefs = {\"download.default_directory\":'C:\\\\Users\\\\kwang648\\\\Downloads\\\\banking'}\n",
    "    options.add_experimental_option(\"prefs\",prefs)\n",
    "    driver = webdriver.Chrome(service=Service(executable_path='C:/Users/kwang648/Downloads/python_code/chromedriver_win32/chromedriver.exe'),options=options)\n",
    "    url = 'https://cdr.ffiec.gov/public/PWS/DownloadBulkData.aspx'\n",
    "    driver.get(url)\n",
    "    #select \"call report\"\n",
    "    products = Select(driver.find_element(By.ID,'ListBox1'))\n",
    "    products.select_by_visible_text('Call Reports -- Single Period')\n",
    "    #select TSV for the format\n",
    "    driver.find_element(By.ID,'TSVRadioButton').click()\n",
    "    for period in quarters:\n",
    "        #drop down to select dates\n",
    "        dropdown = Select(driver.find_element(By.XPATH,'//*[@id=\"DatesDropDownList\"]'))\n",
    "        dropdown.select_by_visible_text(period)\n",
    "        #click download button\n",
    "        download_button = driver.find_element(By.ID,\"Download_0\")\n",
    "        download_button.click()\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03d484ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_filename(directory):\n",
    "    os.chdir(directory)\n",
    "    for item in os.listdir(directory):\n",
    "        if bool(re.search('[0-9]{8}.zip', item)):\n",
    "            new_name = re.findall('[0-9]{8}', item)[0]\n",
    "            new_name = \"call\"+datetime.strptime(new_name, '%m%d%Y').strftime('%y%m')+\".zip\"\n",
    "            os.rename(item,new_name)\n",
    "        if bool(re.search('[a-zA-Z]{4}[0-9]{4}.xpt', item)):\n",
    "            new_name = re.findall('[a-zA-Z]{4}[0-9]{4}.xpt', item)[0]\n",
    "            os.rename(item,new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9eff7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip():\n",
    "    os.chdir(download_folder)\n",
    "    for item in os.listdir(download_folder):\n",
    "        if item.endswith('.zip'):\n",
    "            folder_name = item[:8]\n",
    "            if not os.path.exists(download_folder+folder_name):\n",
    "                os.mkdir(download_folder+folder_name)\n",
    "            file_name = os.path.abspath(item)\n",
    "            zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "            zip_ref.extractall(download_folder+folder_name) # extract file to dir\n",
    "            zip_ref.close() # close file\n",
    "            os.remove(file_name) # delete zipped file\n",
    "    print('unzip complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae357c",
   "metadata": {},
   "source": [
    "Download, rename, and unzip the files for each quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e72a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download():\n",
    "    if start <= datetime.strptime('200012', '%Y%m'):\n",
    "        if end <= datetime.strptime('200012', '%Y%m'):\n",
    "            download_zip(extract_links([url1976_2000]))\n",
    "        elif end <= datetime.strptime('201012', '%Y%m'):\n",
    "            download_zip(extract_links([url1976_2000,url2001_2010]))\n",
    "        elif end <= datetime.strptime('202106', '%Y%m'):\n",
    "            download_zip(extract_links([url1976_2000,url2001_2010,url2011_2021]))\n",
    "        else:\n",
    "            download_zip(extract_links([url1976_2000,url2001_2010,url2011_2021]))\n",
    "            use_selenium(start,end)\n",
    "    elif start <= datetime.strptime('201012', '%Y%m'):\n",
    "        if end <= datetime.strptime('201012', '%Y%m'):\n",
    "            download_zip(extract_links([url2001_2010]))\n",
    "        elif end <= datetime.strptime('202106', '%Y%m'):\n",
    "            download_zip(extract_links([url2001_2010,url2011_2021]))\n",
    "        else:\n",
    "            download_zip(extract_links([url2001_2010,url2011_2021]))\n",
    "            use_selenium(start,end)\n",
    "    elif start <= datetime.strptime('202106', '%Y%m'):\n",
    "        if end <= datetime.strptime('202106','%Y%m'):\n",
    "            download_zip(extract_links([url2011_2021]))\n",
    "        else:\n",
    "            download_zip(extract_links([url2011_2021]))\n",
    "            use_selenium(start,end)\n",
    "    else:\n",
    "        use_selenium(start,end)\n",
    "    print('download zip files complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92857f1a",
   "metadata": {},
   "source": [
    "load variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3346ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_code = pd.read_csv('C:/Users/kwang648/Downloads/call_report_item_new.csv')\n",
    "item_code = item_code.drop(['Notes','Description','citation'],axis=1)\n",
    "#change end period to 2262-04-11 indicating the variable is currently in use\n",
    "item_code['end'] = item_code['end'].apply(lambda x: 22620411 if x==99991231 else x)\n",
    "#convert begin and end period to DateTime type\n",
    "item_code['begin']=pd.to_datetime(item_code['begin'],format='%Y%m%d')\n",
    "item_code['end']=pd.to_datetime(item_code['end'],format='%Y%m%d')\n",
    "item_code = item_code.dropna(subset=['var_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa271e48",
   "metadata": {},
   "source": [
    "extract item code used in the definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf4b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = []\n",
    "for code in item_code['item_code']:\n",
    "    list = re.findall(\"[a-zA-Z0-9]+\",code)\n",
    "    for item in list:\n",
    "        if item not in var_list:\n",
    "            var_list.append(item)\n",
    "var_list.extend(['IDRSSD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252744e6",
   "metadata": {},
   "source": [
    "define data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a61717a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {var:float for var in var_list}\n",
    "dtype_dict.update({'RSSD9010': 'object', 'RSSD9200': 'object','RSSD9220':'object'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d50e14c",
   "metadata": {},
   "source": [
    "Convert text to csv, this function also filters the columns to only keep the columns used in the variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea4ac89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_csv(item):\n",
    "    os.chdir(download_folder+item)\n",
    "    merged = pd.DataFrame()\n",
    "    for text in os.listdir(download_folder+item):\n",
    "        if text == 'Readme.txt':\n",
    "            continue\n",
    "        curr_list =  pd.read_csv(text, delimiter = \"\\t\",on_bad_lines='skip').columns.tolist()\n",
    "        load_list = [element for element in var_list if element in curr_list]\n",
    "        if len(load_list)==1:\n",
    "            continue\n",
    "        new = pd.read_csv(text, delimiter = \"\\t\",usecols=load_list,on_bad_lines='skip')\n",
    "        new['IDRSSD'] = pd.to_numeric(new['IDRSSD'], errors='coerce')\n",
    "        new = new.dropna(subset=['IDRSSD'])\n",
    "        if merged.empty:\n",
    "            merged = new\n",
    "        else:\n",
    "            merged = merged.merge(new,on='IDRSSD',suffixes=('', '_remove'))\n",
    "            merged = merged.loc[:,~merged.columns.str.contains('Unnamed')]\n",
    "    merged.drop([i for i in merged.columns if 'remove' in i],axis=1, inplace=True)\n",
    "    time = int((datetime.strptime(re.findall('[0-9]{4}',item)[0], '%y%m')+relativedelta(day=31)).strftime('%Y%m%d'))\n",
    "    merged['RSSD9999'] = pd.Series([time for x in range(len(merged.index))],dtype=int)\n",
    "    merged.rename(columns={'IDRSSD':'RSSD9001'},inplace=True)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0f7d1",
   "metadata": {},
   "source": [
    "Convert xpt to csv, this function also filters the columns to only keep the items used in the variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92628842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xpt_to_csv(item):\n",
    "    os.chdir(download_folder+item)\n",
    "    for xpt in os.listdir(download_folder+item):\n",
    "        with open(xpt, 'rb') as f:\n",
    "            df = xport.to_dataframe(f)\n",
    "        total_list = df.columns.tolist()\n",
    "        load_list = [element for element in var_list if element in total_list]\n",
    "        df = df[[c for c in df.columns if c in load_list]]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8e3eb",
   "metadata": {},
   "source": [
    "convert and download the csv for each quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d92cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_download():\n",
    "    os.chdir(download_folder)\n",
    "    folder_list = os.listdir(download_folder)\n",
    "    os.mkdir(download_folder+'/csv')\n",
    "    for item in folder_list:\n",
    "        if datetime.strptime(re.findall('[0-9]{4}',item)[0], '%y%m') >= datetime.strptime('202109', '%Y%m'):\n",
    "            new = text_to_csv(item)\n",
    "        else:\n",
    "            new = xpt_to_csv(item)\n",
    "        new.to_csv(download_folder+'csv/'+item+'.csv',index=False)\n",
    "        print('conversion of '+item+' to csv complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0b1449",
   "metadata": {},
   "source": [
    "merge quarters together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff10eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge():\n",
    "    os.chdir(download_folder+'csv/')\n",
    "    merged = pd.DataFrame()\n",
    "    first_time=1\n",
    "    for item in os.listdir(download_folder+'csv/'):\n",
    "        new = dd.read_csv(item,dtype=dtype_dict)\n",
    "        if first_time == 1:\n",
    "            merged = new\n",
    "            first_time = 0\n",
    "        else:\n",
    "            merged = dd.concat([merged,new])\n",
    "    print('merge quarters complete')\n",
    "    return merged.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de13d85b",
   "metadata": {},
   "source": [
    "variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26600991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_code(code,list):\n",
    "    code_list = re.findall(\"[a-zA-Z0-9]+\",code)\n",
    "    for item in code_list:\n",
    "        if item not in list:\n",
    "            print(item+' is not available')\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a842694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_definition(call_report):\n",
    "    call_report.rename(columns={'RSSD9999':'DATE'},inplace=True)\n",
    "    call_report['DATE']=pd.to_datetime(call_report['DATE'],format='%Y%m%d')\n",
    "    for varname in item_code['var_name'].unique():\n",
    "        #find begin and end date\n",
    "        begin = item_code[item_code['var_name']==varname]['begin']\n",
    "        end = item_code[item_code['var_name']==varname]['end']\n",
    "        code = item_code[item_code['var_name']==varname]['item_code']\n",
    "        #handle variable definition with multiple periods\n",
    "        i = 1\n",
    "        while i<=len(begin):\n",
    "            if handle_missing_code(code.iloc[i-1],call_report.columns.to_list()) ==True:\n",
    "                i=i+1\n",
    "                continue\n",
    "            if len(code.iloc[i-1])==8:\n",
    "                call_report.loc[(call_report['DATE']>=begin.iloc[i-1]) &(call_report['DATE']<=end.iloc[i-1]),varname] = call_report[(call_report['DATE']>=begin.iloc[i-1]) &(call_report['DATE']<=end.iloc[i-1])][code.iloc[i-1]]\n",
    "            else:\n",
    "                call_report.loc[(call_report['DATE']>=begin.iloc[i-1]) &(call_report['DATE']<=end.iloc[i-1]),varname] = call_report[(call_report['DATE']>=begin.iloc[i-1]) &(call_report['DATE']<=end.iloc[i-1])].eval(code.iloc[i-1])\n",
    "            i=i+1\n",
    "    call_report.to_csv(download_folder+'call_report.csv',index=False)\n",
    "    print('Variable definition complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a090c",
   "metadata": {},
   "source": [
    "initiate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e881a412",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded all zip files\n",
      "Successfully converted call0003 to csv\n",
      "Successfully converted call0006 to csv\n",
      "Successfully converted call0009 to csv\n",
      "Successfully converted call0012 to csv\n",
      "Successfully converted call0103 to csv\n",
      "Successfully converted call0106 to csv\n",
      "Successfully converted call0109 to csv\n",
      "Successfully converted call0112 to csv\n",
      "Successfully converted call0203 to csv\n",
      "Successfully converted call0206 to csv\n",
      "Successfully converted call0209 to csv\n",
      "Successfully converted call0212 to csv\n",
      "Successfully converted call0303 to csv\n",
      "Successfully converted call0306 to csv\n",
      "Successfully converted call0309 to csv\n",
      "Successfully converted call0312 to csv\n",
      "Successfully converted call0403 to csv\n",
      "Successfully converted call0406 to csv\n",
      "Successfully converted call0409 to csv\n",
      "Successfully converted call0412 to csv\n",
      "Successfully converted call0503 to csv\n",
      "Successfully converted call0506 to csv\n",
      "Successfully converted call0509 to csv\n",
      "Successfully converted call0512 to csv\n",
      "Successfully converted call0603 to csv\n",
      "Successfully converted call0606 to csv\n",
      "Successfully converted call0609 to csv\n",
      "Successfully converted call0612 to csv\n",
      "Successfully converted call0703 to csv\n",
      "Successfully converted call0706 to csv\n",
      "Successfully converted call0709 to csv\n",
      "Successfully converted call0712 to csv\n",
      "Successfully converted call0803 to csv\n",
      "Successfully converted call0806 to csv\n",
      "Successfully converted call0809 to csv\n",
      "Successfully converted call0812 to csv\n",
      "Successfully converted call0903 to csv\n",
      "Successfully converted call0906 to csv\n",
      "Successfully converted call0909 to csv\n",
      "Successfully converted call0912 to csv\n",
      "Successfully converted call1003 to csv\n",
      "Successfully converted call1006 to csv\n",
      "Successfully converted call1009 to csv\n",
      "Successfully converted call1012 to csv\n",
      "Successfully converted call1103 to csv\n",
      "Successfully converted call1106 to csv\n",
      "Successfully converted call1109 to csv\n",
      "Successfully converted call1112 to csv\n",
      "Successfully converted call1203 to csv\n",
      "Successfully converted call1206 to csv\n",
      "Successfully converted call1209 to csv\n",
      "Successfully converted call1212 to csv\n",
      "Successfully converted call1303 to csv\n",
      "Successfully converted call1306 to csv\n",
      "Successfully converted call1309 to csv\n",
      "Successfully converted call1312 to csv\n",
      "Successfully converted call1403 to csv\n",
      "Successfully converted call1406 to csv\n",
      "Successfully converted call1409 to csv\n",
      "Successfully converted call1412 to csv\n",
      "Successfully converted call1503 to csv\n",
      "Successfully converted call1506 to csv\n",
      "Successfully converted call1509 to csv\n",
      "Successfully converted call1512 to csv\n",
      "Successfully converted call1603 to csv\n",
      "Successfully converted call1606 to csv\n",
      "Successfully converted call1609 to csv\n",
      "Successfully converted call1612 to csv\n",
      "Successfully converted call1703 to csv\n",
      "Successfully converted call1706 to csv\n",
      "Successfully converted call1709 to csv\n",
      "Successfully converted call1712 to csv\n",
      "Successfully converted call1803 to csv\n",
      "Successfully converted call1806 to csv\n",
      "Successfully converted call1809 to csv\n",
      "Successfully converted call1812 to csv\n",
      "Successfully converted call1903 to csv\n",
      "Successfully converted call1906 to csv\n",
      "Successfully converted call1909 to csv\n",
      "Successfully converted call1912 to csv\n",
      "Successfully converted call2003 to csv\n",
      "Successfully converted call2006 to csv\n",
      "Successfully converted call2009 to csv\n",
      "Successfully converted call2012 to csv\n",
      "Successfully converted call2103 to csv\n",
      "Successfully converted call2106 to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n",
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (14,16,17,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,64,65,68,71,72,75,76,79,80,83,84,87,88,91,169,170,175,176) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n",
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,160) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n",
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (1,5,11,16,17,18,19,20,21,22,29,82,83,84,85,86,87,88,89) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n",
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (1,7,11,13,24,50,51,52,53,54,55,56,74,75,76) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n",
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (10,12,120,121) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n",
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,16,17,19,20,25,28,29,30,31,32,33,34,71,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,226,227,229,230,235,238,239,240) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n",
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (202,206) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n",
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (1,2,3,4,5,6,7,44,164,165,166,167,168,169,170) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n",
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (1,2,3,4,5,9,10,11,12,13,14,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,71,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,92,93,94,95,96,97,100,101,102,103,104,105,106,107,108,110,111,112,113,115,116,117,118,119,120,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n",
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (1,2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n",
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted call2109 to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (1,2,3,4,5,9,10,11,12,13,14,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,71,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,92,93,94,95,96,97,100,101,102,103,104,105,106,107,108,110,111,112,113,115,116,117,118,119,120,121,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted call2112 to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kwang648\\AppData\\Local\\Temp\\ipykernel_16112\\1821176184.py:7: DtypeWarning: Columns (1,2,3,4,5,9,10,11,12,13,14,17,18,19,20,21,22,23,24,26,27,28,29,31,32,33,34,35,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,71,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,92,93,94,95,96,97,100,101,102,103,104,105,106,107,108,110,111,112,113,115,116,117,118,119,120,121,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  new = text_to_csv(item)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted call2203 to csv\n",
      "Successfully converted call9803 to csv\n",
      "Successfully converted call9806 to csv\n",
      "Successfully converted call9809 to csv\n",
      "Successfully converted call9812 to csv\n",
      "Successfully converted call9903 to csv\n",
      "Successfully converted call9906 to csv\n",
      "Successfully converted call9909 to csv\n",
      "Successfully converted call9912 to csv\n",
      "Successfully merged all the quarters\n",
      "RSSD9999 is not available\n",
      "RCFD0900 is not available\n",
      "RCFD0900 is not available\n",
      "Successfully created variable definitions and stored it in call_report.csv\n"
     ]
    }
   ],
   "source": [
    "download()\n",
    "rename_filename(download_folder)\n",
    "unzip()\n",
    "for item in os.listdir(download_folder):\n",
    "    rename_filename(download_folder+item)\n",
    "convert_download()\n",
    "merged = merge()\n",
    "variable_definition(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627bc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
