{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652d9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "import xport, csv\n",
    "import pandas as pd\n",
    "from pandas.api.types import infer_dtype\n",
    "from datetime import datetime\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.select import Select\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756323f9",
   "metadata": {},
   "source": [
    "Define the urls to extract from and the download folder directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7aa545",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1976_2000 = 'https://www.chicagofed.org/banking/financial-institution-reports/commercial-bank-data-complete-1976-2000'\n",
    "url2001_2010 = 'https://www.chicagofed.org/banking/financial-institution-reports/commercial-bank-data-complete-2001-2010'\n",
    "url2011_2021 = 'https://www.chicagofed.org/banking/financial-institution-reports/commercial-bank-structure-data'\n",
    "root = 'https://www.chicagofed.org/'\n",
    "download_folder = 'C:/Users/kwang648/Downloads/banking/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48d3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '201803'\n",
    "end = '202203'\n",
    "start =  datetime.strptime(start, '%Y%m')\n",
    "end =  datetime.strptime(end, '%Y%m')\n",
    "quarters = (pd.date_range(start,end + pd.offsets.QuarterBegin(1), freq='Q').strftime('%y%m').tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ab3f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1803',\n",
       " '1806',\n",
       " '1809',\n",
       " '1812',\n",
       " '1903',\n",
       " '1906',\n",
       " '1909',\n",
       " '1912',\n",
       " '2003',\n",
       " '2006',\n",
       " '2009',\n",
       " '2012',\n",
       " '2103',\n",
       " '2106',\n",
       " '2109',\n",
       " '2112',\n",
       " '2203']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f524a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_links(url_list):\n",
    "    print(url_list)\n",
    "    zip_files = []\n",
    "    for url in url_list:\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        all_hrefs = soup.find_all('a')\n",
    "        all_links = [link.get('href') for link in all_hrefs]\n",
    "        temp = [dl for dl in all_links if '.zip' in dl or '.ZIP' in dl]\n",
    "        temp = [dl.lower() for dl in temp]\n",
    "        temp = [dl[:dl.index('.zip')+len('.zip')] for dl in temp]\n",
    "        for dl in temp:\n",
    "            zip_files.append(dl)\n",
    "    return zip_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fab9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_zip(zip_files):\n",
    "    #if download folder does not exist, create one\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "\n",
    "    for zip_file in zip_files:\n",
    "        if re.findall(\"[0-9]{4}\",zip_file)[0] in quarters:\n",
    "            full_url = root + zip_file\n",
    "            r = requests.get(full_url)\n",
    "            zip_filename = os.path.basename(zip_file)\n",
    "            dl_path = os.path.join(download_folder, zip_filename)\n",
    "            with open(dl_path, 'wb') as z_file:\n",
    "                z_file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6c10e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method is used to extract the links after 202106\n",
    "def use_selenium(start,end):  \n",
    "    if start >= datetime.strptime('202109', '%Y%m'):\n",
    "        quarters = (pd.date_range(start, end + pd.offsets.QuarterBegin(1), freq='Q').strftime('%m/%d/%Y').tolist())\n",
    "    else:\n",
    "        quarters = (pd.date_range(pd.to_datetime('202109',format='%Y%m'), pd.to_datetime(end) + pd.offsets.QuarterBegin(1), freq='Q').strftime('%m/%d/%Y').tolist())\n",
    "    # Create Driver Instance\n",
    "    options = webdriver.ChromeOptions()\n",
    "    prefs = {\"download.default_directory\":download_folder}\n",
    "    options.add_experimental_option(\"prefs\",prefs)\n",
    "    driver = webdriver.Chrome(service=Service(executable_path='C:/Users/kwang648/Downloads/python_code/chromedriver_win32/chromedriver.exe'),options=options)\n",
    "    url = 'https://cdr.ffiec.gov/public/PWS/DownloadBulkData.aspx'\n",
    "    driver.get(url)\n",
    "    #select \"call report\"\n",
    "    products = Select(driver.find_element(By.ID,'ListBox1'))\n",
    "    products.select_by_visible_text('Call Reports -- Single Period')\n",
    "    #select TSV for the format\n",
    "    driver.find_element(By.ID,'TSVRadioButton').click()\n",
    "    for period in quarters:\n",
    "        #drop down to select dates\n",
    "        dropdown = Select(driver.find_element(By.XPATH,'//*[@id=\"DatesDropDownList\"]'))\n",
    "        dropdown.select_by_visible_text(period)\n",
    "        #click download button\n",
    "        download_button = driver.find_element(By.ID,\"Download_0\")\n",
    "        download_button.click()\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d484ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_filename():\n",
    "    os.chdir(download_folder)\n",
    "    for item in os.listdir(download_folder):\n",
    "        if bool(re.search('[0-9]{8}', item)):\n",
    "            new_name = re.findall('[0-9]{8}', item)[0]\n",
    "            new_name = \"call\"+datetime.strptime(new_name, '%m%d%Y').strftime('%y%m')+\".zip\"\n",
    "            os.rename(item,new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eff7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip():\n",
    "    os.chdir(download_folder)\n",
    "    for item in os.listdir(download_folder):\n",
    "        if item.endswith('.zip'):\n",
    "            folder_name = item[:8]\n",
    "            if not os.path.exists(download_folder+folder_name):\n",
    "                os.mkdir(download_folder+folder_name)\n",
    "            file_name = os.path.abspath(item)\n",
    "            zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "            zip_ref.extractall(download_folder+folder_name) # extract file to dir\n",
    "            zip_ref.close() # close file\n",
    "            os.remove(file_name) # delete zipped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e72a3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.chicagofed.org/banking/financial-institution-reports/commercial-bank-structure-data']\n"
     ]
    }
   ],
   "source": [
    "if start <= datetime.strptime('200012', '%Y%m'):\n",
    "    if end <= datetime.strptime('200012', '%Y%m'):\n",
    "        download_zip(extract_links([url1976_2000]))\n",
    "    elif end <= datetime.strptime('201012', '%Y%m'):\n",
    "        download_zip(extract_links([url1976_2000,url2001_2010]))\n",
    "    elif end <= datetime.strptime('202106', '%Y%m'):\n",
    "        download_zip(extract_links([url1976_2000,url2001_2010,url2011_2021]))\n",
    "    else:\n",
    "        download_zip(extract_links([url1976_2000,url2001_2010,url2011_2021]))\n",
    "        use_selenium(start,end)\n",
    "elif start <= datetime.strptime('201012', '%Y%m'):\n",
    "    if end <= datetime.strptime('201012', '%Y%m'):\n",
    "        download_zip(extract_links([url2001_2010]))\n",
    "    elif end <= datetime.strptime('202106', '%Y%m'):\n",
    "        download_zip(extract_links([url2001_2010,url2011_2021]))\n",
    "    else:\n",
    "        download_zip(extract_links([url2001_2010,url2011_2021]))\n",
    "        use_selenium(start,end)\n",
    "elif start <= datetime.strptime('202106', '%Y%m'):\n",
    "    if end <= datetime.strptime('202106','%Y%m'):\n",
    "        download_zip(extract_links([url2011_2021]))\n",
    "    else:\n",
    "        download_zip(extract_links([url2011_2021]))\n",
    "        use_selenium(start,end)\n",
    "else:\n",
    "    use_selenium(start,end)\n",
    "rename_filename()\n",
    "unzip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92857f1a",
   "metadata": {},
   "source": [
    "load variable definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3346ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_code = pd.read_csv('C:/Users/kwang648/Downloads/call_report_item_new.csv')\n",
    "item_code = item_code.drop(['Notes','Description','citation'],axis=1)\n",
    "#change end period to 2262-04-11 indicating the variable is currently in use\n",
    "item_code['end'] = item_code['end'].apply(lambda x: 22620411 if x==99991231 else x)\n",
    "#convert begin and end period to DateTime type\n",
    "item_code['begin']=pd.to_datetime(item_code['begin'],format='%Y%m%d')\n",
    "item_code['end']=pd.to_datetime(item_code['end'],format='%Y%m%d')\n",
    "item_code = item_code.dropna(subset=['var_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa271e48",
   "metadata": {},
   "source": [
    "extract item code used in the definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf4b805",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = []\n",
    "for code in item_code['item_code']:\n",
    "    list = re.findall(\"[a-zA-Z0-9]+\",code)\n",
    "    for item in list:\n",
    "        if item not in var_list:\n",
    "            var_list.append(item)\n",
    "var_list.extend(['Date','Entity','ENTITY','DT','ID_RSSD','dt','id_rssd','IDRSSD', 'FDIC Certificate Number', 'OCC Charter Number', 'OTS Docket Number', 'Primary ABA Routing Number', 'Financial Institution Name', 'Financial Institution Address', 'Financial Institution City', 'Financial Institution State', 'Financial Institution Zip Code', 'Financial Institution Filing Type', 'Last Date/Time Submission Updated On'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d50e14c",
   "metadata": {},
   "source": [
    "Convert text to csv, and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e0c0f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(download_folder)\n",
    "folder_list = os.listdir(download_folder)\n",
    "for item in folder_list:\n",
    "    if datetime.strptime(re.findall('[0-9]{4}',item)[0], '%y%m') >= datetime.strptime('202109', '%Y%m'):\n",
    "        os.chdir(download_folder+item)\n",
    "        merged = pd.DataFrame()\n",
    "        for text in os.listdir(download_folder+item):\n",
    "            if text == 'Readme.txt':\n",
    "                #os.remove(text)\n",
    "                continue\n",
    "            if merged.empty:\n",
    "                merged = pd.read_csv(text, delimiter = \"\\t\",on_bad_lines='skip')\n",
    "                merged['IDRSSD'] = pd.to_numeric(merged['IDRSSD'], errors='coerce')\n",
    "            else:\n",
    "                curr_list =  pd.read_csv(text, delimiter = \"\\t\",on_bad_lines='skip').columns.tolist()\n",
    "                load_list = [element for element in var_list if element in curr_list]\n",
    "                if len(load_list)==1:\n",
    "                    #os.remove(text)\n",
    "                    continue\n",
    "                new = pd.read_csv(text, delimiter = \"\\t\",usecols=load_list,on_bad_lines='skip')\n",
    "                new['IDRSSD'] = pd.to_numeric(new['IDRSSD'], errors='coerce')\n",
    "                merged = merged.merge(new,on='IDRSSD',suffixes=('', '_remove'))\n",
    "                merged = merged.loc[:,~merged.columns.str.contains('Unnamed')]\n",
    "                merged = merged.dropna(subset=['IDRSSD'])\n",
    "                merged.to_csv(download_folder+item+'.csv')\n",
    "            #os.remove(text)\n",
    "        merged.drop([i for i in merged.columns if 'remove' in i],axis=1, inplace=True)\n",
    "        merged['Reporting Period End Date'] = pd.Series([datetime.strptime(re.findall('[0-9]{4}',item)[0], '%Y%m')+relativedelta(day=31) for x in range(len(df.index))])\n",
    "        merged.to_csv(download_folder+item+'.csv')\n",
    "    else:\n",
    "        os.chdir(download_folder+item)\n",
    "        for xpt in os.listdir(download_folder+item):\n",
    "            with open(xpt, 'rb') as f:\n",
    "                df = xport.to_dataframe(f)\n",
    "            total_list = df.columns.tolist()\n",
    "            load_list = [element for element in var_list if element in total_list]\n",
    "            df = df[[c for c in df.columns if c in load_list]]\n",
    "            df.to_csv(download_folder+item+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a70d051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6413ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
